<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>How to use a pretrained deep learning model for additive manufacturing porosity</title>
    <link rel="stylesheet" href="/dragonfly3dworld/design.css">
    <link href="https://cdn.jsdelivr.net/npm/HarmonyOS_Sans_SC@1.0.3/HarmonyOS_Sans_SC.min.css" rel="stylesheet"/>
    <style>
        .video-container {
            position: relative;
            padding-bottom: 56.25%; /* 16:9 高宽比 */
            height: 0;
            overflow: hidden;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
        }
    </style>
</head>
<body>
    <button id="mode-toggle">Toggle Mode</button>

    <div class="container">
        <h1>How to use a pretrained deep learning model for additive manufacturing porosity - (English)</h1>
        <p>This instructional video demonstrates how to use and improve a pre-trained deep learning model for detecting porosity and defects in additive manufacturing samples, emphasizing the importance of intensity scale calibration and showing how transfer learning can enhance model performance for specific datasets.</p>

        <div class="card">
            <h2>Tutorial Content</h2>
            <h1>Using Pre-trained Deep Learning Models for Additive Manufacturing Porosity Detection [00:00:03]</h1>
<h2>Introduction [00:00:03]</h2>
<p>This tutorial demonstrates how to use ORS's pre-trained deep learning model for additive manufacturing porosity or defect detection. The process involves properly calibrating intensity scales and using transfer learning to adapt the model to your specific data.</p>
<h2>Calibrating Intensity Scales [00:00:24]</h2>
<p>For the model to work properly, you need to calibrate the intensity scales:</p>
<ol>
<li>Right-click on the loaded image channel</li>
<li>Select <code>calibrate intensity scale</code></li>
<li>Use the century scale (preloaded in Dragonfly)</li>
<li>This sets the background peak to 0 and the material peak to 100</li>
<li>The histogram can be enlarged and adjusted (precise positioning isn't critical)</li>
</ol>
<p>The calibration makes the model more widely applicable across different datasets since the deep learning model was trained on data where the background peak is at 0 and the material peak is at 100.</p>
<p>After calibration, the contrast will change significantly. To adjust the view:<br />
- Go to <code>main</code> and reset the contrast across the range<br />
- Or use the triangle shortcut and select inside the object</p>
<h2>Applying the Pre-trained Model [00:02:41]</h2>
<p>To apply an existing model:</p>
<ol>
<li>Go to the <code>segment</code> tab and select <code>segment with AI</code></li>
<li>The pre-trained models aren't immediately available - you need to create a model in your system first</li>
<li>Open the <code>deep learning tool</code></li>
<li>Create a new model:</li>
<li>Click on the architecture dropdown box</li>
<li>Select <code>pre-trained by the Dragonfly team</code></li>
<li>In the value dropdown box, select <code>AM defect model version 1.0</code></li>
<li>Click <code>generate</code></li>
</ol>
<p>Once the model is created, you can segment your data:<br />
- The model will output three classes in multi-ROI format<br />
- You can toggle the background and material off to see where defects are segmented</p>
<h2>Using Transfer Learning [00:05:14]</h2>
<p>If your AM parts have been scanned with different parameters than what the model was trained on (different material, CT scan quality, detector, etc.), you can use transfer learning to adapt the model to your specific case:</p>
<ol>
<li>Go to <code>artificial intelligence segmentation wizard</code></li>
<li>Adjust the contrast for better visualization</li>
<li>Select a slice to use for training</li>
<li>Generate a new model:</li>
<li>Click on the architecture dropdown</li>
<li>Select the pre-trained AM defect model</li>
<li>Mark the selected frame as a training frame</li>
<li>Add the necessary classes:</li>
<li>Class 1: Pores</li>
<li>Class 2: Material</li>
<li>Class 3: Background/Exterior</li>
</ol>
<h2>Creating Training Data [00:07:45]</h2>
<p>To provide ground truth data for one frame:</p>
<ol>
<li>For the exterior (background):</li>
<li>Select the exterior class</li>
<li>Use the smart grid tool (hold Ctrl and scroll to adjust size)</li>
<li>Hold left mouse button and paint the outside of the material</li>
<li>
<p>Refine edges as needed</p>
</li>
<li>
<p>For the pores:</p>
</li>
<li>Select the pores class</li>
<li>Use the local Otsu tool</li>
<li>The smaller the circle around a pore, the more accurate the segmentation</li>
<li>Add pixels by holding Ctrl + left click</li>
<li>
<p>Remove pixels by holding Shift + left click</p>
</li>
<li>
<p>For the material:</p>
</li>
<li>Right-click on material and select <code>add all unlabeled voxels to class</code></li>
</ol>
<h2>Training the Model [00:11:27]</h2>
<ol>
<li>Select a different frame as a monitoring frame to observe results during training</li>
<li>Click <code>train</code></li>
<li>The model will begin training, starting with the pre-trained weights and adding your new data</li>
<li>Training typically converges within 10-15 epochs</li>
<li>The process may take around 20 minutes depending on your hardware</li>
<li>Once complete, give your model a name and publish it</li>
</ol>
<h2>Testing the Improved Model [00:15:25]</h2>
<p>To test the improved model:</p>
<ol>
<li>Go to <code>segment with AI</code></li>
<li>Select your newly trained model</li>
<li>Preview on a single frame or segment all slices</li>
<li>Examine the results by toggling between classes in the multi-ROI view</li>
</ol>
<p>The improved model should provide better segmentation results for your specific data and can be applied to all similar scans.</p>
<h2>Conclusion [00:16:30]</h2>
<p>This transfer learning approach allows you to adapt pre-trained models to your specific additive manufacturing data. The model only needs to be trained once for all similar samples, saving significant time in the long run. You can continue to refine the model by adding more training frames if needed.</p>
<p>For further improvements, consider sharing your data with the ORS team to help enhance the pre-trained model, making it more robust for future users.</p>
        </div>

        <div class="card">
            <h2>Source of Information</h2>
            <ul>
<li>Original YouTube video: <a href="https://www.youtube.com/watch?v=enkLJhnlG5k">How to use a pretrained deep learning model for additive manufacturing porosity</a></li>
<li>Language: English</li>
<li>Processed on: 2025-04-22 14:56:28 Eastern Daylight Time</li>
<li>Processing Tool: Custom Python Script</li>
</ul>
            
            <!-- YouTube Video Embed (if available) -->
            <div class="video-container">
    <iframe src="https://www.youtube-nocookie.com/embed/enkLJhnlG5k"
            title="YouTube video player" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            referrerpolicy="strict-origin-when-cross-origin"
            allowfullscreen></iframe>
</div>
        </div>
    </div>

    <footer>
        <p>Author: Dragonfly</p>
        <a href="https://x.com/ai_dragonfly" target="_blank">Twitter/X</a>
        <p>&copy; 2025 copyright</p>
    </footer>

    <script src="/dragonfly3dworld/interactive.js"></script>
</body>
</html>