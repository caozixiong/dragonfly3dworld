<!DOCTYPE html>
<html lang="{{ language }}">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{{ title }}</title>
    <link rel="stylesheet" href="{{ css_path }}">
    <link href="https://cdn.jsdelivr.net/npm/HarmonyOS_Sans_SC@1.0.3/HarmonyOS_Sans_SC.min.css" rel="stylesheet"/>
    <style>
        .video-container {
            position: relative;
            padding-bottom: 56.25%; /* 16:9 高宽比 */
            height: 0;
            overflow: hidden;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
        }
    </style>
</head>
<body>
    <button id="mode-toggle">Toggle Mode</button>

    <div class="container">
        <h1>{{ header }}</h1>
        <p>{{ intro_text }}</p>

        <div class="card">
            <h2>Tutorial Content</h2>
            <h1>预训练模型释放：骨骼微CT数据案例研究</h1>
<h2>介绍 [00:01:27]</h2>
<p>预训练模型使用迁移学习，即从一个领域获取知识并应用到另一个领域。这类似于个体之间的知识传递，比如猴子向人展示如何使用工具打开坚果。在深度学习中，预训练模型允许我们利用关于特定任务的现有知识，并将这些知识转移到新的应用中。</p>
<p>预训练模型首次在Dragonfly 2022.2版本中发布。这些模型存在于不同的架构中，最初并非为语义分割而训练。用户可以使用这些"原始"模型，并针对他们特定的分割任务进行训练。使用预训练模型的优势包括：</p>
<ul>
<li>提高性能</li>
<li>更快的收敛速度</li>
<li>减少训练时间</li>
</ul>
<h2>评估预训练模型 [00:04:44]</h2>
<p>这项研究的目标是评估预训练模型相比未训练模型的优势。测试了三种模型：</p>
<ol>
<li>未训练模型 - 随机初始化的经典UNET</li>
<li>ORS500K - 在多种不同科学数据上训练的模型（微CT、电子显微镜等）</li>
<li>Bone500K - 仅用灰度骨骼图像训练的模型</li>
</ol>
<p>测试使用的数据包括三个数据集：<br />
- 黑猩猩骨骼样本<br />
- 人类股骨近端<br />
- 人类股骨远端</p>
<p>对于每个训练集，使用了几个切片（约10个）的骨骼样本及其对应的骨骼分割。训练使用一个切片、四个切片或60个点进行。测试在空白切片上进行，以评估模型在整个切片上的性能。</p>
<h2>性能结果 [00:06:24]</h2>
<p>使用DICE分数（预测分割与真实分割之间相似性的度量）来评估性能。DICE分数越高表示性能越好。</p>
<p>对于所有测试的数据集，预训练模型始终显著优于未训练模型。专门在骨骼数据上训练的Bone500K模型通常比ORS500K模型表现更好，尤其是在较大的训练数据集上。</p>
<p>在检查训练周期内的验证DICE分数时，预训练模型显示出明显更快的收敛速度。即使在最早的训练周期，预训练模型也比未训练模型获得了更高的性能。此外，即使在延长训练（250个周期）后，未训练模型也从未达到与预训练模型相同的准确度。</p>
<h2>校准强度尺度 [00:10:49]</h2>
<p>使用来自多个来源的数据的预训练模型的一个重要方面是校准强度尺度。Dragonfly中的"校准强度尺度"工具允许训练深度学习模型而无需标准化数据集，这样就不会改变图像。</p>
<p>该工具自动识别主要区域（如背景和骨骼）并使用这些值在深度学习模型中进行校准。这种方法在处理来自不同来源且可能具有不同直方图分布的数据集时特别有价值。</p>
<p>在校准数据时，软件将强度值转换为标准化尺度（类似于摄氏度如何标准化温度）。例如，骨密度可能设置为100单位，空气密度设置为0单位。这种校准不会改变实际数据，但会标准化深度学习模型解释数据的方式。</p>
<h2>在Dragonfly中查找预训练模型 [00:15:38]</h2>
<p>要在Dragonfly中访问预训练模型：</p>
<ol>
<li>进入深度学习工具</li>
<li>创建新模型</li>
<li>选择"由Dragonfly团队预训练"</li>
<li>从可用模型中选择</li>
</ol>
<p>有各种预训练模型架构可用，包括不同深度的UNET和Sensor3D。这些模型已准备好在您特定的分割任务上进行训练。</p>
<h2>通用士兵项目 [00:16:41]</h2>
<p>通用士兵项目旨在创建一个模型，可以以无监督方式跨不同动物和不同体素大小分割骨骼样本。这将使研究人员能够专注于科学而非分割任务。</p>
<p>该项目拥有来自各种动物的不同扫描库，分辨率各异，包括：<br />
- 骨骼数据存储库<br />
- 尸体农场动物数据（人类股骨）<br />
- 骨骼病理学收藏<br />
- Maud Abbott博物馆收藏</p>
<p>扫描范围跨越广泛的体素大小尺度，这对创建通用骨骼分割工具很重要。校准对该项目至关重要，以确保模型适用于任何包含骨骼的数据集。</p>
<h2>通用士兵的初步结果 [00:18:13]</h2>
<p>在对六个不同分辨率的骨骼样本测试通用士兵模型时，Bone500K预训练模型仍然优于未训练和ORS500K模型。这表明校准方法和跨不同样本的训练即使在模型从未见过的数据上也能产生良好的结果。</p>
<h2>结论 [00:19:14]</h2>
<p>预训练模型在骨骼分割任务中始终优于未训练模型。特定的预训练模型如Bone500K可以为特定领域的应用提供额外的好处。未来可能会为不同的成像模式创建其他专业模型。</p>
<p>使用预训练模型的主要优势包括：<br />
- 零额外成本的更好性能<br />
- 显著更快的训练收敛<br />
- 即使在有限的训练数据下也能改善结果</p>
<p>对于通用士兵项目，Bone500K模型可能会作为基础。更多的训练数据总是会带来更好的结果，因此欢迎贡献带有分割的数据集。</p>
<p>预训练模型代表了图像分割深度学习的重大进步，使研究人员能够以更少的训练数据和时间获得更好的结果。</p>
        </div>

        <div class="card">
            <h2>Source of Information</h2>
            <ul>
<li>Original YouTube video: <a href="https://www.youtube.com/watch?v=63li5pUElh4">Pretrained Models Unleashed: A Case Study With Bone MicroCT Data</a></li>
<li>Language: Chinese</li>
<li>Processed on: 2025-04-22 01:29:43 Eastern Daylight Time</li>
<li>Processing Tool: Custom Python Script</li>
</ul>
            
            <!-- YouTube Video Embed (if available) -->
            
        </div>
    </div>

    <footer>
        <p>Author: {{ footer.author }}</p>
        <a href="{{ footer.social_link }}" target="_blank">{{ footer.social_text }}</a>
        <p>&copy; {{ footer.copyright_year }} {{ footer.copyright_text }}</p>
    </footer>

    <script src="{{ js_path }}"></script>
</body>
</html>