<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>July 2022 Workshop Video 9: Segmentation Wizard part 1 - English Tutorial</title>
    <link rel="stylesheet" href="/dragonfly3dworld/design.css">
    <link href="https://cdn.jsdelivr.net/npm/HarmonyOS_Sans_SC@1.0.3/HarmonyOS_Sans_SC.min.css" rel="stylesheet"/>
    <style>
        .video-container {
            position: relative;
            padding-bottom: 56.25%; /* 16:9 高宽比 */
            height: 0;
            overflow: hidden;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
        }
    </style>
</head>
<body>
    <button id="mode-toggle">Toggle Mode</button>

    <div class="container">
        <h1>July 2022 Workshop Video 9: Segmentation Wizard part 1 - (English)</h1>
        <p>This tutorial demonstrates how to use the segmentation wizard tool in Dragonfly to create quick segmentations using sparse training data with machine learning algorithms like random forest, and then progress to training a U-Net model for improved results on a Lego figurine example.</p>

        <div class="card">
            <h2>Tutorial Content</h2>
            <h1>Using the Segmentation Wizard for Sparse Training</h1>
<h2>Introduction [00:00:03]</h2>
<p>This tutorial demonstrates how to use the segmentation wizard for sparse training with limited training data. The segmentation wizard provides a quick way to segment data using machine learning algorithms like random forest without requiring extensive deep learning training.</p>
<h2>Loading the Sample Data [00:00:15]</h2>
<p>For this demonstration, we'll be using a scan of a Lego figurine. The segmentation wizard helps make the training of models simpler and easier, allowing you to add and compare different models and incrementally add training data.</p>
<h2>Starting the Segmentation Wizard [00:00:49]</h2>
<ol>
<li>Navigate to <code>Artificial Intelligence</code> in the menu</li>
<li>Select <code>Segmentation Wizard</code></li>
<li>Choose the data labeled "original"</li>
</ol>
<p>A new window will open, creating a second Dragonfly context. This interface is designed to simplify the model training process.</p>
<h2>Creating the Initial Training Frame [00:01:36]</h2>
<ol>
<li>Click the <code>+</code> button to add a new frame for training</li>
<li>Define your classes:</li>
<li>Rename the first class to "background"</li>
<li>Rename the second class to "plastic"</li>
<li>Use the 2D paintbrush tool to mark some pixels:</li>
<li>Paint some areas as background</li>
<li>Paint some areas as plastic (the Lego figure)</li>
</ol>
<p>This sparse data approach means we're only marking a small subset of pixels rather than the entire image.</p>
<h2>Training the Initial Models [00:02:52]</h2>
<ol>
<li>Click on <code>Train</code> to begin the training process</li>
<li>Select the "Quick Start" strategy</li>
<li>This trains three models: two random forest models and one U-Net model</li>
<li>Note: The U-Net model requires fully segmented frames, so it won't train with sparse data</li>
</ol>
<p>The system will train the random forest models and display their predictions. Both models should provide reasonably good segmentations of the Lego figure.</p>
<h2>Reviewing and Selecting a Model [00:04:36]</h2>
<p>After training, you'll see two different predictions from the random forest models at the bottom of the screen:</p>
<ol>
<li>Compare the results of both models</li>
<li>Select the better model by clicking the promotion button</li>
<li>This promotes the segmentation into the current frame</li>
<li>You can now make minor corrections to the segmentation if needed</li>
</ol>
<h2>Iterative Improvement Process [00:05:58]</h2>
<p>The key workflow of the segmentation wizard is iterative improvement:</p>
<ol>
<li>Your first frame is now fully segmented (all pixels are classified)</li>
<li>Scroll to a different slice and add it as a new frame</li>
<li>The existing models will automatically make predictions on this new frame</li>
<li>Select the better prediction and promote it</li>
<li>Make any necessary corrections to improve the segmentation</li>
<li>Repeat this process with additional frames to strengthen your model</li>
</ol>
<h2>Training a U-Net Model [00:08:30]</h2>
<p>Once you have multiple fully segmented frames:</p>
<ol>
<li>Add a new frame as a monitoring frame</li>
<li>Disable the random forest models</li>
<li>Enable the U-Net model</li>
<li>Click <code>Train</code> to train the neural network using your fully segmented frames</li>
</ol>
<p>The U-Net model typically provides more accurate results than random forest models, especially for complex segmentation tasks.</p>
<h2>Monitoring Training Progress [00:10:17]</h2>
<p>During training:</p>
<ol>
<li>Monitor the loss values, which should decrease and approach zero</li>
<li>Small increases in loss may occur but should eventually decrease again</li>
<li>Decreasing loss indicates model improvement</li>
<li>You can stop training when the model performance is satisfactory</li>
</ol>
<h2>Exporting and Using the Model [00:11:34]</h2>
<p>When you're satisfied with the model:</p>
<ol>
<li>Exit the segmentation wizard</li>
<li>When prompted, select "Publish selected models"</li>
<li>The model will be saved with the name you provided</li>
</ol>
<p>To apply the model to your data:</p>
<ol>
<li>Go to the <code>Segmentation</code> tab</li>
<li>Select <code>Segment with AI</code></li>
<li>Choose your trained model</li>
<li>Click <code>Preview</code> to test on the current slice or <code>Segment all slices</code> to process the entire volume</li>
<li>After segmentation, you can extract the "plastic" class as a region of interest (ROI)</li>
<li>From this ROI, you can create a mesh, visualize in 3D, or perform other operations</li>
</ol>
<h2>Conclusion [00:13:03]</h2>
<p>The segmentation wizard provides a streamlined workflow for creating segmentation models with limited training data. Starting with sparse annotations and random forest models, you can iteratively improve your segmentation and eventually train a more powerful U-Net model for better results.</p>
<p>This tutorial demonstrated a simple two-class example. For more complex segmentation tasks with multiple classes, the same principles apply but may require more training data and iterations.</p>
        </div>

        <div class="card">
            <h2>Source of Information</h2>
            <ul>
<li>Original YouTube video: <a href="https://www.youtube.com/watch?v=4fiatoh-I48">July 2022 Workshop Video 9: Segmentation Wizard part 1</a></li>
<li>Language: English</li>
<li>Processed on: 2025-04-22 22:56:26 Eastern Daylight Time</li>
<li>Processing Tool: Custom Python Script</li>
</ul>
            
            <!-- YouTube Video Embed (if available) -->
            <div class="video-container">
    <iframe src="https://www.youtube-nocookie.com/embed/4fiatoh-I48"
            title="YouTube video player" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            referrerpolicy="strict-origin-when-cross-origin"
            allowfullscreen></iframe>
</div>
        </div>
    </div>

    <footer>
        <p>Author: Dragonfly</p>
        <a href="https://x.com/ai_dragonfly" target="_blank">Twitter/X</a>
        <p>&copy; 2025 copyright</p>
    </footer>

    <script src="/dragonfly3dworld/interactive.js"></script>
</body>
</html>