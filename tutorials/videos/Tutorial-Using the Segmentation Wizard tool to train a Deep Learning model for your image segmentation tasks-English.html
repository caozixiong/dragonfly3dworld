<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Using the Segmentation Wizard tool to train a Deep Learning model for your image segmentation tasks. - English Tutorial</title>
    <link rel="stylesheet" href="/dragonfly3dworld/design.css">
    <link href="https://cdn.jsdelivr.net/npm/HarmonyOS_Sans_SC@1.0.3/HarmonyOS_Sans_SC.min.css" rel="stylesheet"/>
    <style>
        .video-container {
            position: relative;
            padding-bottom: 56.25%; /* 16:9 高宽比 */
            height: 0;
            overflow: hidden;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
        }
    </style>
</head>
<body>
    <button id="mode-toggle">Toggle Mode</button>

    <div class="container">
        <h1>Using the Segmentation Wizard tool to train a Deep Learning model for your image segmentation tasks. - (English)</h1>
        <p>This hands-on workshop demonstrates how to use the segmentation wizard in Dragonfly software to train deep learning models for image segmentation tasks, focusing on the workflow for creating training frames, labeling data, and generating models to automatically segment various structures in medical and scientific imaging.</p>

        <div class="card">
            <h2>Tutorial Content</h2>
            <h2>Introduction to Deep Learning Segmentation in Dragonfly [00:00:11]</h2>
<p>This tutorial demonstrates how to use deep learning, particularly the segmentation wizard in Dragonfly, to train a model for image segmentation tasks. The main objective is to show the complete workflow for segmenting structures in medical or scientific imaging data.</p>
<p>The tutorial will focus on:<br />
- Preparing data for deep learning<br />
- Using the segmentation wizard<br />
- Creating training frames<br />
- Training a segmentation model<br />
- Applying the model to new data</p>
<h2>Data Preparation and Normalization [00:02:21]</h2>
<p>Before starting with deep learning, it's important to prepare your data properly. This tutorial uses a dental CT (Cone Beam CT) dataset as an example.</p>
<h3>Examining the Data</h3>
<p>First, examine your dataset to understand its properties:</p>
<ul>
<li>Check the intensity range using the range tool (stretcher tool)</li>
<li>Assess whether structures of interest have consistent intensity values</li>
<li>Determine if conventional thresholding would work for your segmentation task</li>
</ul>
<p>In this dental CT example, the teeth have varying intensities - front teeth have higher intensity while back teeth have lower intensity. Simple thresholding would not work well because:<br />
- Using a low threshold connects teeth that should be separate<br />
- Using a high threshold misses the back teeth with lower intensity</p>
<h3>Data Normalization</h3>
<p>For deep learning to work effectively, data normalization is often required:</p>
<ol>
<li>Check your data format by right-clicking on the image in the list panel and selecting "Image Properties"</li>
<li>Note the data type (e.g., unsigned 16-bit integer, float)</li>
<li>For non-float data, normalize using the Convert tool:</li>
<li>Go to <code>Modify &gt; Transform &gt; Convert</code></li>
<li>Set the input range to match your data's actual intensity range</li>
<li>Set the output range to 0-1 (float format)</li>
<li>Check "Create new image" to preserve your original data</li>
</ol>
<p>For example, if your data is in 16-bit format (range 0-65535) but the actual intensities only span 0-10000, normalize this actual range to 0-1.</p>
<p>For DICOM data with negative values (like HU units), you may need to adjust the offset to properly normalize the data.</p>
<h2>Using the Segmentation Wizard [00:26:05]</h2>
<p>The segmentation wizard provides a streamlined workflow for creating deep learning segmentation models.</p>
<h3>Starting the Wizard</h3>
<ol>
<li>Right-click on your normalized dataset</li>
<li>Select "Segmentation Wizard" from the context menu</li>
</ol>
<h3>Creating Training Frames</h3>
<p>The wizard opens with three tabs, with "Frames" being the main tab for creating training data:</p>
<ol>
<li>Click "Create Frame" to add a new training frame</li>
<li>The frame appears as a region on your current slice</li>
<li>This region will be used for training the model</li>
</ol>
<p>Each frame needs both input (image data) and output (labeling). By default, two classes are created:<br />
- One for background<br />
- One for the structure of interest</p>
<p>You can rename classes to better identify them (e.g., "Teeth" instead of "Class A").</p>
<h3>Manually Segmenting Frames</h3>
<p>Use the ROI Painter tools to label structures in your frames:</p>
<ul>
<li>Use the brush tool with range option enabled to paint only within specific intensity ranges</li>
<li>Paint all areas belonging to your structure of interest</li>
<li>Use the fill tool to fill enclosed areas</li>
<li>Add unlabeled voxels to the background class by right-clicking the background class and selecting "Add all unlabeled voxels to the class"</li>
</ul>
<p>For effective training:<br />
- Create multiple frames (3-5 is typically sufficient)<br />
- Select different slices that represent the variability in your data<br />
- Be precise with your manual segmentation</p>
<h3>Tips for Efficient Painting</h3>
<ul>
<li>To prevent accidental modification of certain classes, select only the classes you want to modify</li>
<li>Hold Ctrl while painting to add to the first selected class</li>
<li>Hold Shift while painting to remove from the first class and add to the second class</li>
<li>The brush color changes to indicate which class you're painting</li>
</ul>
<h2>Training a Deep Learning Model [00:40:22]</h2>
<p>Once you have created and labeled your frames, you can train a deep learning model:</p>
<h3>Setting Up the Model</h3>
<ol>
<li>Go to the "Models" tab</li>
<li>Click "Add Model"</li>
<li>Select "UNet" as the model type</li>
<li>Set the level to "Full" for better results</li>
</ol>
<h3>Training Parameters</h3>
<p>In newer versions of Dragonfly (2020.2+), you can modify training parameters:</p>
<ul>
<li>Patch size: Increase for larger structures (64 or 128 instead of default 32)</li>
<li>Early stopping: Enables automatic stopping when training no longer improves</li>
<li>Epochs: Number of training iterations</li>
</ul>
<p>For most segmentation tasks, the default parameters work well to start with.</p>
<h3>Training Process</h3>
<ol>
<li>Click "Train" to start the training process</li>
<li>The wizard shows a graph of the loss function during training</li>
<li>The loss function should decrease over time, indicating improving performance</li>
<li>Training typically takes 10-20 epochs to show good results</li>
</ol>
<p>The training time depends on:<br />
- Number and size of frames<br />
- Complexity of the structures<br />
- Patch size<br />
- Hardware capabilities (GPU)</p>
<h3>Evaluating the Model</h3>
<p>After training:<br />
1. Create a new frame on a slice not used for training<br />
2. Click "Predict" to apply the model to this frame<br />
3. Examine the prediction quality<br />
4. If needed, make corrections to the prediction and use it as an additional training frame<br />
5. Retrain the model with the additional frame</p>
<h2>Advanced Features and Tips [00:57:16]</h2>
<h3>Multi-Class Segmentation</h3>
<p>You can add more classes to segment multiple structures:</p>
<ol>
<li>Add a new class in the frames tab</li>
<li>Note that adding a new class will reset your model</li>
<li>Label the new structure in your frames</li>
<li>Train a new model with the additional class</li>
</ol>
<p>For example, you can segment both teeth and bones by creating separate classes for each.</p>
<h3>Using Existing Segmentations</h3>
<p>If you already have manually segmented ROIs:</p>
<ol>
<li>Create a dense multi-ROI from your existing ROIs</li>
<li>In the segmentation wizard, create a frame</li>
<li>Use "Fill from object" and select your multi-ROI</li>
<li>This will transfer your existing segmentation into the frame</li>
</ol>
<h3>Model Types</h3>
<p>Dragonfly offers several types of deep learning models:</p>
<ul>
<li>2D UNet: Works on individual slices</li>
<li>Multi-slice UNet (2.5D): Uses adjacent slices for context (up to 11 slices)</li>
<li>3D UNet: Uses 3D volumes (32×32×32 cubes) but requires more computational resources</li>
</ul>
<p>For most applications, 2D or multi-slice UNet provides a good balance of accuracy and speed.</p>
<h3>Frame Size Considerations</h3>
<ul>
<li>Don't create frames that are too large (includes unnecessary regions)</li>
<li>Don't create frames that are too small (insufficient context)</li>
<li>Focus on the region containing your structures of interest</li>
<li>Larger structures generally benefit from larger patch sizes</li>
</ul>
<h2>Conclusion [01:26:20]</h2>
<p>The segmentation wizard in Dragonfly provides a streamlined workflow for creating deep learning models to segment complex structures in medical and scientific imaging data. By creating a few well-labeled frames, you can train models that generalize to segment entire volumes.</p>
<p>Key points to remember:<br />
- Properly normalize your data before training<br />
- Create 3-5 well-labeled frames for initial training<br />
- Start with default parameters and adjust as needed<br />
- Iteratively improve your model by adding more training frames<br />
- Save your trained model to use it on the entire volume</p>
<p>While deep learning may not work perfectly for all datasets, the segmentation wizard makes it accessible to users without extensive programming experience. With practice and experimentation, you can develop effective models for your specific segmentation tasks.</p>
        </div>

        <div class="card">
            <h2>Source of Information</h2>
            <ul>
<li>Original YouTube video: <a href="https://www.youtube.com/watch?v=WexO2kCK2uU">Using the Segmentation Wizard tool to train a Deep Learning model for your image segmentation tasks.</a></li>
<li>Language: English</li>
<li>Processed on: 2025-04-23 08:13:02 Eastern Daylight Time</li>
<li>Processing Tool: Custom Python Script</li>
</ul>
            
            <!-- YouTube Video Embed (if available) -->
            <div class="video-container">
    <iframe src="https://www.youtube-nocookie.com/embed/WexO2kCK2uU"
            title="YouTube video player" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            referrerpolicy="strict-origin-when-cross-origin"
            allowfullscreen></iframe>
</div>
        </div>
    </div>

    <footer>
        <p>Author: Dragonfly</p>
        <a href="https://x.com/ai_dragonfly" target="_blank">Twitter/X</a>
        <p>&copy; 2025 copyright</p>
    </footer>

    <script src="/dragonfly3dworld/interactive.js"></script>
</body>
</html>