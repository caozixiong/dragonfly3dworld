<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>July 2022 Workshop Video 10: Segmentation Wizard Part 2 - English Tutorial</title>
    <link rel="stylesheet" href="/dragonfly3dworld/design.css">
    <link href="https://cdn.jsdelivr.net/npm/HarmonyOS_Sans_SC@1.0.3/HarmonyOS_Sans_SC.min.css" rel="stylesheet"/>
    <style>
        .video-container {
            position: relative;
            padding-bottom: 56.25%; /* 16:9 高宽比 */
            height: 0;
            overflow: hidden;
            margin-top: 20px;
            margin-bottom: 20px;
        }
        
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
        }
    </style>
</head>
<body>
    <button id="mode-toggle">Toggle Mode</button>

    <div class="container">
        <h1>July 2022 Workshop Video 10: Segmentation Wizard Part 2 - (English)</h1>
        <p>This video demonstrates how to use Segmentation Wizard to train a UNET neural network model for distinguishing between small and large fibers in a denim micro CT scan, a task that cannot be accomplished with traditional thresholding methods.</p>

        <div class="card">
            <h2>Tutorial Content</h2>
            <h2>Introduction to Segmentation Wizard for Deep Learning [00:00:04]</h2>
<p>This is the second Segmentation Wizard video, focusing on using deep learning for segmentation of a denim sample that was micro CT scanned by Rigaku. This example demonstrates the power of deep learning for segmentation tasks that traditional methods cannot handle effectively.</p>
<p>The sample contains large and small fibers that are visually distinguishable but cannot be separated using traditional thresholding or segmentation methods. This makes it a perfect candidate for deep learning segmentation using a UNET model through Segmentation Wizard.</p>
<h2>Launching Segmentation Wizard [00:01:05]</h2>
<p>To begin the process:</p>
<ol>
<li>Navigate to <code>Artificial Intelligence</code> &gt; <code>Segmentation Wizard</code></li>
<li>This launches a new context window dedicated to the Segmentation Wizard</li>
</ol>
<h2>Creating Training Data [00:01:28]</h2>
<p>To train the neural network, we need to paint one or more slices to create ground truth data:</p>
<ol>
<li>Create a frame for painting</li>
<li>Define the classes needed for segmentation:</li>
<li>Background</li>
<li>Small fibers</li>
<li>Large fibers</li>
</ol>
<p>For effective training, all pixels in the slice must be marked with their appropriate class.</p>
<h3>Painting Tools Available:</h3>
<ul>
<li><strong>2D Paintbrush Tool</strong>: Basic painting</li>
<li><strong>Full Paintbrush Tool</strong>: Complete coverage</li>
<li><strong>Local OTSU Lower</strong>: Selects lower-valued pixels within the brush radius</li>
<li><strong>Local OTSU Upper</strong>: Selects higher-valued pixels within the brush radius</li>
<li><strong>Exclusive Brush</strong>: Allows toggling between selected classes</li>
</ul>
<h3>Painting Techniques:</h3>
<ol>
<li><strong>Background Painting</strong>:</li>
<li>Use the Local OTSU Lower brush for the black background areas</li>
<li>
<p>For efficiency, you can use the right-click option <code>Add all unlabeled voxels to class</code> at the end</p>
</li>
<li>
<p><strong>Fiber Painting</strong>:</p>
</li>
<li>Use Local OTSU Upper for large fibers</li>
<li>Paint small fibers carefully to distinguish them from large ones</li>
<li>
<p>Use the Undo button if needed to correct mistakes</p>
</li>
<li>
<p><strong>Fine-tuning</strong>:</p>
</li>
<li>Use the Exclusive Brush by holding Ctrl and clicking on multiple classes</li>
<li>Shift key adds the current class and removes the other</li>
<li>
<p>Ctrl key does the opposite</p>
</li>
<li>
<p><strong>Visualization Tips</strong>:</p>
</li>
<li>Adjust opacity to see the underlying data while painting</li>
<li>Higher opacity helps identify incorrectly labeled pixels</li>
</ol>
<h2>Training the Model [00:08:24]</h2>
<p>Once the training frame is properly labeled:</p>
<ol>
<li>Select the frame as a training frame</li>
<li>Add another frame as a monitoring frame to track progress</li>
<li>Go to <code>Train</code></li>
<li>Select <code>Go directly to UNET</code> rather than Quick Start</li>
<li>Choose a model type (Single Model 1 is faster for demonstration, but Single Model 2 is generally a better choice)</li>
</ol>
<p>The UNET training window will appear showing:<br />
- Training parameters<br />
- Model description<br />
- Training details<br />
- Preview frame<br />
- Monitoring frame (if selected)</p>
<p>As training progresses:<br />
- The preview frames will show the current segmentation result<br />
- The loss values will decrease as the model improves<br />
- You can adjust the inference and input opacity sliders to better visualize results</p>
<h2>Improving the Model [00:12:04]</h2>
<p>After initial training, you can:</p>
<ol>
<li>Make the model prediction visible using the visibility button</li>
<li>Evaluate the results on the monitoring frame</li>
<li>Fix up any misclassified areas using the painting tools</li>
<li>Promote the corrected frame to a training frame</li>
<li>Add more training frames from different areas of the dataset</li>
<li>Continue training to improve the model</li>
</ol>
<p>This iterative process allows you to:<br />
- Gradually improve the model's accuracy<br />
- Add more diverse training data<br />
- Focus on problematic areas</p>
<h2>Applying the Trained Model [00:22:18]</h2>
<p>Once you're satisfied with the training:</p>
<ol>
<li>Stop the training (either manually or let it stop automatically)</li>
<li>Save the model with a descriptive name</li>
<li>Apply the model through the Segmentation tab:</li>
<li>Go to <code>Segment with AI</code></li>
<li>Select your saved model</li>
<li>Apply a preview to a slice or segment all slices</li>
</ol>
<h2>Best Practices and Tips [00:20:57]</h2>
<ul>
<li><strong>Training Duration</strong>: Allow the model to train for at least 10 epochs, preferably until performance plateaus</li>
<li><strong>Early Stopping</strong>: The system will implement early stopping if no improvement is detected (configurable)</li>
<li><strong>Ground Truth Quality</strong>: Better ground truth leads to faster and better model training</li>
<li><strong>Multiple Training Frames</strong>: Use frames from different parts of the dataset for more robust models</li>
<li><strong>Iterative Improvement</strong>: Continue adding training data and refining the model as needed</li>
</ul>
<h2>Conclusion [00:23:12]</h2>
<p>Segmentation Wizard provides a powerful way to train deep learning models for segmentation tasks that traditional methods cannot handle. By painting ground truth data and iteratively training the model, you can achieve high-quality segmentation results even for challenging datasets.</p>
<p>This demonstration showed a segmentation model that transforms an image into a multi-ROI segmentation. The next video will cover regression models, which transform images into other images.</p>
        </div>

        <div class="card">
            <h2>Source of Information</h2>
            <ul>
<li>Original YouTube video: <a href="https://www.youtube.com/watch?v=ItzKszpHxCQ">July 2022 Workshop Video 10: Segmentation Wizard Part 2</a></li>
<li>Language: English</li>
<li>Processed on: 2025-04-22 21:19:01 Eastern Daylight Time</li>
<li>Processing Tool: Custom Python Script</li>
</ul>
            
            <!-- YouTube Video Embed (if available) -->
            <div class="video-container">
    <iframe src="https://www.youtube-nocookie.com/embed/ItzKszpHxCQ"
            title="YouTube video player" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
            referrerpolicy="strict-origin-when-cross-origin"
            allowfullscreen></iframe>
</div>
        </div>
    </div>

    <footer>
        <p>Author: Dragonfly</p>
        <a href="https://x.com/ai_dragonfly" target="_blank">Twitter/X</a>
        <p>&copy; 2025 copyright</p>
    </footer>

    <script src="/dragonfly3dworld/interactive.js"></script>
</body>
</html>